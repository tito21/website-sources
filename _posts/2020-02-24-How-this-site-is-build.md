---
layout: post
title: "How this site is build"
slug: "how-site-build"
date: 2020-02-24 20:20:20 -0300
draft: true
categories: ["Python", "pandoc", "github", "english"]
tags: ["markdown", "site generator", "pandoc", "websites"]
description: This site is generated using pandoc managed by a set of python
             scripts.
---

The old version of this site was hosted on Github pages and manage using Jekyll.
That system worked very well, I could write blog post on Markdown, easily tweak
the CSS and HTML of the theme and the website was always updated on every
commit. It only have one problem: Jekyll is written in Ruby. This is (imo) a
major problem as you have to manage a local Ruby environment, which can be
difficult if you don't really use it for anything else. I also think the whole
Jekyll ecosystem is a bit overkill for just converting Markdown to HTML
especially in light of tools like [pandoc](https://pandoc.org).

With this in mind I decided to write my own tool for generating websites. All it
really is a python script for running pandoc with custom arguments. I first
wrote a pandoc template to use a the foundation for the website that supports
all the features I needed for my website (namely MathJax, syntax highlighting
and general webpage footer and headers). Then the posts are converted to HTML
using pandoc.

## Using pandoc to fill in variables


## Hosting on Github

As I have no budged for a website every thing is hosted on Github. The site
itself it a user's github at [https://github.com/tito21/tito21.github.io] and
all the sources at [https://github.com/tito21/website-sources]


# Extra: generating `robots.txt` and `sitemap.xml`

One of the true advantages of a system like Jekyll is the ability to easily add
plugins. A `sitemap.xml` is generated with the website. Hopefully this can be
replaced with a pure python script. The script works by finding every HTML file
in the site's folder and then using the `xml.etree` module to create a xml
representation according to the [sitemaps.org] schema. `robots.txt` is then
generated by simply making the appropriate file.

<script src="https://gist.github.com/tito21/f9ae856eee2f3f41b4da1490238a9097.js"></script>